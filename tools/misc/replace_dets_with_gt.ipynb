{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl    \n",
    "import os\n",
    "from pcdet.ops.iou3d_nms import iou3d_nms_utils\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "os.chdir('/home/cgriesbacher/thesis/3DTrans/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ious(pseudo_labels, gt_labels):\n",
    "    #add iou score to the dataframe, default is 0\n",
    "    pseudo_labels = pseudo_labels.assign(iou = 0)\n",
    "    pseudo_labels = pseudo_labels.assign(true_label = \"Background\")\n",
    "    pseudo_labels = pseudo_labels.assign(gt_id = -1)\n",
    "    gt_labels = gt_labels.assign(iou = 0)\n",
    "\n",
    "    #det detection frame ids\n",
    "    ps_frame_ids = pseudo_labels['frame_id'].unique()\n",
    "\n",
    "    # Loop over all frames\n",
    "    for ps_frame_id in tqdm.tqdm(ps_frame_ids):\n",
    "\n",
    "        gt_labels_frame = gt_labels[gt_labels['frame_id'] == ps_frame_id]\n",
    "        pseudo_labels_frame = pseudo_labels[pseudo_labels['frame_id'] == ps_frame_id]\n",
    "\n",
    "        if len(gt_labels_frame) == 0 or len(pseudo_labels_frame) == 0:\n",
    "            #print(f\"Frame {ps_frame_id} has no gts or no detections\")\n",
    "            continue\n",
    "\n",
    "        # Convert the boxes to numpy\n",
    "        gt_boxes_frame = np.stack(gt_labels_frame[\"gt_boxes_lidar\"].values)\n",
    "        ps_boxes_frame = np.stack(pseudo_labels_frame[\"boxes_lidar\"].values)\n",
    "\n",
    "        #iou_matrix = iou3d_nms_utils.boxes_iou3d_gpu(torch.tensor(gt_boxes_frame, dtype=torch.float, device='cuda'), torch.tensor(ps_boxes_frame, dtype=torch.float, device='cuda')).cpu().numpy()\n",
    "        iou_matrix = iou3d_nms_utils.boxes_iou_bev(torch.tensor(gt_boxes_frame, dtype=torch.float, device='cuda'), torch.tensor(ps_boxes_frame, dtype=torch.float, device='cuda')).cpu().numpy()\n",
    "        #iou_matrix = iou3d_nms_utils.boxes_bev_iou_cpu(gt_boxes_frame, ps_boxes_frame)\n",
    "        \n",
    "        # Get the max iou for each det box\n",
    "        max_ious_ps = np.max(iou_matrix, axis=0)\n",
    "        max_ious_ps_idx = np.argmax(iou_matrix, axis=0)\n",
    "\n",
    "        detection_mask = max_ious_ps > 0\n",
    "        max_ious_ps = max_ious_ps[detection_mask]\n",
    "        max_ious_ps_idx = max_ious_ps_idx[detection_mask]\n",
    "        pseudo_labels_frame_masked = pseudo_labels_frame[detection_mask]\n",
    "\n",
    "        # get class for each detection\n",
    "        cls_dets = gt_labels_frame['names'].values[max_ious_ps_idx]\n",
    "        gt_id_dets = gt_labels_frame['gt_id'].values[max_ious_ps_idx]\n",
    "\n",
    "        \n",
    "        # Update the iou score and gt_id for each detection in the original DataFrame\n",
    "        pseudo_labels.loc[pseudo_labels_frame_masked.index, 'iou'] = max_ious_ps\n",
    "        pseudo_labels.loc[pseudo_labels_frame_masked.index, 'gt_id'] = gt_id_dets\n",
    "\n",
    "        pseudo_labels.loc[pseudo_labels_frame_masked.index, 'true_label'] = cls_dets\n",
    "        # print(f\"Percentage of detection ious greater than 0: {round(len(max_ious_ps[max_ious_ps > 0])/len(max_ious_ps),2)}\")\n",
    "\n",
    "        # Get max_iou for each gt box\n",
    "        max_ious_gts = np.max(iou_matrix, axis=1)\n",
    "\n",
    "        # Update the iou score for each gt in the original DataFrame\n",
    "        gt_labels.loc[gt_labels_frame.index, 'iou'] = max_ious_gts\n",
    "        #percentage of ious that are greater than 0\n",
    "        # print(f\"Percentage of gt ious greater than 0: {round(len(max_ious_gts[max_ious_gts > 0])/len(max_ious_gts),2)}\")\n",
    "\n",
    "        # XXX: only update if score is higher than current score\n",
    "\n",
    "\n",
    "    iou_thresholds = [0.1, 0.3, 0.5, 0.7]\n",
    "\n",
    "    #for each detection, add detected_0.3, detected_0.5, detected_0.7\n",
    "    for iou_threshold in iou_thresholds:\n",
    "        pseudo_labels[f'detected_{iou_threshold}'] = pseudo_labels['iou'] >= iou_threshold\n",
    "        gt_labels[f'detected_{iou_threshold}'] = gt_labels['iou'] >= iou_threshold\n",
    "\n",
    "    return pseudo_labels, gt_labels\n",
    "\n",
    "\n",
    "def load_detections(path, df, train_dataset=None, eval_dataset=None):\n",
    "    with open(path, 'rb') as f:\n",
    "        dets = pkl.load(f)\n",
    "\n",
    "    #make a dataframe\n",
    "    df_dets_dataset = pd.DataFrame(dets)\n",
    "    \n",
    "    #get datasset name from path\n",
    "    if eval_dataset == None:\n",
    "        eval_dataset = path.split('/')[-2]\n",
    "    if train_dataset == None:\n",
    "        train_dataset = path.split('/')[-8].split('_')[0]\n",
    "\n",
    "    #add a column with the dataset name\n",
    "    df_dets_dataset['eval_dataset'] = eval_dataset\n",
    "    df_dets_dataset['train_dataset'] = train_dataset\n",
    "\n",
    "    cols_to_explode = ['name', 'score', 'boxes_lidar', 'pred_labels', 'train_dataset', 'eval_dataset', 'frame_id']\n",
    "    exploded_list = [df_dets_dataset[col].explode() for col in cols_to_explode]\n",
    "    exploded_df = pd.concat(exploded_list, axis=1)\n",
    "\n",
    "    # Adding non-exploded columns\n",
    "    for col in df_dets_dataset.columns:\n",
    "        if col not in cols_to_explode:\n",
    "            exploded_df[col] = df[col].values[0]\n",
    "\n",
    "    # Reset index if needed\n",
    "    df_det_expl = exploded_df.reset_index(drop=True)\n",
    "\n",
    "    df_det_expl = df_det_expl.dropna()\n",
    "\n",
    "    df_new = pd.concat([df, df_det_expl], axis=0)\n",
    "    df_new = df_new.reset_index(drop=True)\n",
    "\n",
    "    print(\"loaded {} detections on dataset {} with model trained on {}\".format(len(df_det_expl), eval_dataset, train_dataset))\n",
    "\n",
    "    return df_new.copy()\n",
    "\n",
    "\n",
    "def load_gt_labels(split):\n",
    "\n",
    "    assert split in ['train', 'val']\n",
    "    dataset_names = [\"avltruck\", \"avlrooftop\", \"zod\"]\n",
    "\n",
    "    #annotation paths\n",
    "    annotation_path_avltruck = \"/home/cgriesbacher/thesis/3DTrans/data/avltruck/avl_infos_\"+split+\".pkl\"\n",
    "    annotation_path_avlrooftop = \"/home/cgriesbacher/thesis/3DTrans/data/avlrooftop/avl_infos_\"+split+\".pkl\"\n",
    "    annotation_path_zod = \"/home/cgriesbacher/thesis/3DTrans/data/zod/zod_infos_\"+split+\"_full.pkl\"\n",
    "\n",
    "    #load the annotations and make a dataframe\n",
    "    with open(annotation_path_avltruck, 'rb') as f:\n",
    "        annotations_avltruck = pkl.load(f)\n",
    "    with open(annotation_path_avlrooftop, 'rb') as f:\n",
    "        annotations_avlrooftop = pkl.load(f)\n",
    "    with open(annotation_path_zod, 'rb') as f:\n",
    "        annotations_zod = pkl.load(f)\n",
    "\n",
    "    avltruck_content = []\n",
    "    for i in range(len(annotations_avltruck)):\n",
    "        content = {}\n",
    "        content[\"names\"] = annotations_avltruck[i][\"annos\"]['name']\n",
    "        content[\"gt_boxes_lidar\"] = annotations_avltruck[i][\"annos\"]['gt_boxes_lidar']\n",
    "        content['dataset'] = dataset_names[0]\n",
    "        content['frame_id'] = annotations_avltruck[i][\"point_cloud\"]['lidar_idx']\n",
    "        avltruck_content.append(content)\n",
    "\n",
    "    avlrooftop_content = []\n",
    "    for i in range(len(annotations_avlrooftop)):\n",
    "        content = {}\n",
    "        content[\"names\"] = annotations_avlrooftop[i][\"annos\"]['name']\n",
    "        content[\"gt_boxes_lidar\"] = annotations_avlrooftop[i][\"annos\"]['gt_boxes_lidar']\n",
    "        content['dataset'] = dataset_names[1]\n",
    "        content['frame_id'] = annotations_avlrooftop[i][\"point_cloud\"]['lidar_idx']\n",
    "        avlrooftop_content.append(content)\n",
    "\n",
    "    zod_content = []\n",
    "    for i in range(len(annotations_zod)):\n",
    "        content = {}\n",
    "        content[\"names\"] = annotations_zod[i][\"annos\"]['name']\n",
    "        content[\"gt_boxes_lidar\"] = annotations_zod[i][\"annos\"]['gt_boxes_lidar']\n",
    "        content['dataset'] = dataset_names[2]\n",
    "        content['frame_id'] = annotations_zod[i][\"point_cloud\"]['lidar_idx']\n",
    "        zod_content.append(content)\n",
    "\n",
    "    #make a dataframe\n",
    "    df_avltruck_annos = pd.DataFrame(avltruck_content)\n",
    "    df_avlrooftop_annos = pd.DataFrame(avlrooftop_content)\n",
    "    df_zod_annos = pd.DataFrame(zod_content)\n",
    "\n",
    "    #make a dataframe with all results\n",
    "    df_annos_full = pd.concat([df_avltruck_annos, df_avlrooftop_annos, df_zod_annos], axis=0) \n",
    "    df_annos_full = df_annos_full.reset_index(drop=True)\n",
    "\n",
    "    #explode the lists\n",
    "    cols_to_explode = ['names', 'gt_boxes_lidar', 'dataset', 'frame_id']\n",
    "    df_annos_lists = [df_annos_full[col].explode() for col in cols_to_explode]\n",
    "    df_annos_full = pd.concat(df_annos_lists, axis=1)\n",
    "\n",
    "    prev_len = len(df_annos_full)\n",
    "    df_annos_full.dropna(inplace=True)\n",
    "    print(f\"Dropped {prev_len - len(df_annos_full)} rows with NaNs\")\n",
    "\n",
    "\n",
    "    namemap_avltruck = {\n",
    "        \"Vehicle_Drivable_Car\": \"Vehicle\",\n",
    "        \"Vehicle_Drivable_Van\": \"Vehicle\",\n",
    "        \"Vehicle_Ridable_Motorcycle\": \"Cyclist\",\n",
    "        \"Vehicle_Ridable_Bicycle\": \"Cyclist\",\n",
    "        \"Human\": \"Pedestrian\",\n",
    "        \"LargeVehicle_Bus\": \"Truck\",\n",
    "        \"LargeVehicle_TruckCab\": \"Truck\",\n",
    "        \"LargeVehicle_Truck\": \"Truck\",\n",
    "        \"Trailer\": \"Truck\",\n",
    "        \"Dont_Care\": \"DontCare\",\n",
    "        \"Other\": \"DontCare\",\n",
    "        #'Placeholder': 'DontCare',\n",
    "    }\n",
    "\n",
    "    namemap_avlrooftop =  {\n",
    "        \"Vehicle_Drivable_Car\": \"Vehicle\",\n",
    "        \"Vehicle_Drivable_Van\": \"Vehicle\",\n",
    "        \"LargeVehicle_Truck\": \"Truck\",\n",
    "        \"LargeVehicle_TruckCab\": \"Truck\",\n",
    "        \"LargeVehicle_Bus\": \"Truck\",\n",
    "        \"LargeVehicle_Bus_Bendy\": \"Truck\",\n",
    "        \"Trailer\": \"Truck\",\n",
    "        \"Vehicle_Ridable_Motorcycle\": \"Cyclist\",\n",
    "        \"Vehicle_Ridable_Bicycle\": \"Cyclist\",\n",
    "        \"Human\": \"Pedestrian\",\n",
    "        \"PPObject\": \"DontCare\",\n",
    "        \"PPObject_Stroller\": \"DontCare\",\n",
    "        \"Dont_care\": \"DontCare\",\n",
    "        #'Placeholder': 'DontCare',\n",
    "    }\n",
    "\n",
    "    namemap_zod = {\n",
    "        \"Vehicle_Car\": \"Vehicle\",\n",
    "        \"Vehicle_Van\": \"Vehicle\",\n",
    "        \"Vehicle_Truck\": \"Truck\",\n",
    "        \"Vehicle_Trailer\": \"Truck\",\n",
    "        \"Vehicle_Bus\": \"Truck\",\n",
    "        \"Vehicle_HeavyEquip\": \"Truck\",\n",
    "        \"Vehicle_TramTrain\": \"Truck\",\n",
    "        \"VulnerableVehicle_Motorcycle\": \"Cyclist\",\n",
    "        \"VulnerableVehicle_Bicycle\": \"Cyclist\",\n",
    "        \"Pedestrian\": \"Pedestrian\",\n",
    "        #'Placeholder': 'DontCare',\n",
    "    }\n",
    "\n",
    "    #apply name maps for all data of each dataset\n",
    "    df_annos_full['names'] = df_annos_full['names'].apply(lambda x: namemap_avltruck[x] if x in namemap_avltruck.keys() else x)\n",
    "    df_annos_full['names'] = df_annos_full['names'].apply(lambda x: namemap_avlrooftop[x] if x in namemap_avlrooftop.keys() else x)\n",
    "    df_annos_full['names'] = df_annos_full['names'].apply(lambda x: namemap_zod[x] if x in namemap_zod.keys() else x)\n",
    "\n",
    "    #drop all dont cares\n",
    "    df_annos_full = df_annos_full[df_annos_full['names'] != 'DontCare']\n",
    "\n",
    "    return df_annos_full\n",
    "\n",
    "def store_detections_with_gt_boxes(detections, gt_labels, folder_name, split):\n",
    "    #store the detections with the gt boxes\n",
    "    detections_with_gt_boxes = detections.copy()\n",
    "    detections_with_gt_boxes = detections_with_gt_boxes.merge(gt_labels[['gt_id', 'frame_id', 'gt_boxes_lidar']], on=['gt_id', 'frame_id'], how='left', suffixes=('', '_gt'))\n",
    "\n",
    "    # dict for each frame with keys name, score, boxes_lidar, pred_labels, frame_id\n",
    "    detections_with_gt_boxes_per_frame = {}\n",
    "    for frame_id in detections_with_gt_boxes['frame_id'].unique():\n",
    "        detections_with_gt_boxes_per_frame[frame_id] = {}\n",
    "\n",
    "        detections_with_gt_boxes_frame = detections_with_gt_boxes[detections_with_gt_boxes['frame_id'] == frame_id]\n",
    "\n",
    "        detections_with_gt_boxes_per_frame[frame_id]['name'] = detections_with_gt_boxes_frame['name'].values\n",
    "        detections_with_gt_boxes_per_frame[frame_id]['score'] = detections_with_gt_boxes_frame['score'].values\n",
    "        detections_with_gt_boxes_per_frame[frame_id]['boxes_lidar'] = detections_with_gt_boxes_frame['boxes_lidar'].values\n",
    "        detections_with_gt_boxes_per_frame[frame_id]['pred_labels'] = detections_with_gt_boxes_frame['pred_labels'].values\n",
    "        detections_with_gt_boxes_per_frame[frame_id]['frame_id'] = detections_with_gt_boxes_frame['frame_id'].values\n",
    "        detections_with_gt_boxes_per_frame[frame_id]['gt_boxes_lidar'] = detections_with_gt_boxes_frame['gt_boxes_lidar'].values\n",
    "\n",
    "    #store the detections with gt boxes\n",
    "    with open(f\"/home/cgriesbacher/thesis/3DTrans/gace/gace_output/{folder_name}/detections_with_gt_boxes_{split}.pkl\", 'wb') as f:\n",
    "        pkl.dump(detections_with_gt_boxes_per_frame, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "gt_labels_all = load_gt_labels(split)\n",
    "gt_labels_all[\"dataset\"].value_counts()\n",
    "#add a gt id to each gt per frame\n",
    "gt_labels_all['gt_id'] = gt_labels_all.groupby(['dataset', 'frame_id']).cumcount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"2023-12-18_15-16-02\"     #avltrck -> ZOD\n",
    "\n",
    "source_dataset_name = \"avltruck\"\n",
    "target_dataset_name = \"zod\"\n",
    "\n",
    "results_path_avltruck = \"/home/cgriesbacher/thesis/3DTrans/gace/gace_output/\"+folder_name+\"/det_annos.pkl\"\n",
    "detections_no_gace = pd.DataFrame()\n",
    "detections_no_gace = load_detections(results_path_avltruck, detections_no_gace, train_dataset=source_dataset_name, eval_dataset=target_dataset_name)\n",
    "\n",
    "#add a detection id to each detection per frame\n",
    "detections_no_gace['det_id'] = detections_no_gace.groupby(['frame_id']).cumcount()\n",
    "\n",
    "detections_all = detections_no_gace.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597/597 [00:02<00:00, 228.70it/s]\n",
      "100%|██████████| 562/562 [00:01<00:00, 361.14it/s]\n",
      "100%|██████████| 455/455 [00:00<00:00, 513.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#reduce gt labels to frames that are in the detections\n",
    "gt_labels_all = gt_labels_all[gt_labels_all['frame_id'].isin(detections_all['frame_id'].unique())]\n",
    "\n",
    "#add x, y, range, angle\n",
    "detections_all['x'] = detections_all['boxes_lidar'].apply(lambda x: x[0])\n",
    "detections_all['y'] = detections_all['boxes_lidar'].apply(lambda x: x[1])\n",
    "detections_all['range'] = np.sqrt(detections_all['x']**2 + detections_all['y']**2)\n",
    "detections_all['angle'] = np.arctan2(detections_all['y'], detections_all['x'])*180/np.pi\n",
    "\n",
    "gt_labels_all['x'] = gt_labels_all['gt_boxes_lidar'].apply(lambda x: x[0])\n",
    "gt_labels_all['y'] = gt_labels_all['gt_boxes_lidar'].apply(lambda x: x[1])\n",
    "gt_labels_all['range'] = np.sqrt(gt_labels_all['x']**2 + gt_labels_all['y']**2)\n",
    "gt_labels_all['angle'] = np.arctan2(gt_labels_all['y'], gt_labels_all['x'])*180/np.pi\n",
    "\n",
    "\n",
    "#align datasets\n",
    "min_angle = -60\n",
    "max_angle = 60\n",
    "max_range = 140\n",
    "\n",
    "detections_all = detections_all[(detections_all['angle'] >= min_angle) & (detections_all['angle'] <= max_angle)]\n",
    "detections_all = detections_all[detections_all['range'] < max_range]\n",
    "\n",
    "gt_labels_all = gt_labels_all[(gt_labels_all['angle'] >= min_angle) & (gt_labels_all['angle'] <= max_angle)]\n",
    "gt_labels_all = gt_labels_all[gt_labels_all['range'] < max_range]\n",
    "\n",
    "#filter frames with no gts or detections\n",
    "detections_all = detections_all[detections_all['frame_id'].isin(gt_labels_all['frame_id'].unique())]\n",
    "gt_labels_all = gt_labels_all[gt_labels_all['frame_id'].isin(detections_all['frame_id'].unique())]\n",
    "\n",
    "detections_all.reset_index(drop=True, inplace=True)\n",
    "gt_labels_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#calc ious\n",
    "detections_vehicles = detections_all[detections_all['name'] == 'Vehicle']\n",
    "gt_labels_vehicles = gt_labels_all[gt_labels_all['names'] == 'Vehicle']\n",
    "detections_vehicles, gt_labels_vehicles = calc_ious(detections_vehicles, gt_labels_vehicles)\n",
    "\n",
    "\n",
    "detectoins_predestrians = detections_all[detections_all['name'] == 'Pedestrian']\n",
    "gt_labels_predestrians = gt_labels_all[gt_labels_all['names'] == 'Pedestrian']\n",
    "detections_pedestrians, gt_labels_pedestrians = calc_ious(detectoins_predestrians, gt_labels_predestrians)\n",
    "\n",
    "detections_cyclists = detections_all[detections_all['name'] == 'Cyclist']\n",
    "gt_labels_cyclists = gt_labels_all[gt_labels_all['names'] == 'Cyclist']\n",
    "detections_cyclists, gt_labels_cyclists = calc_ious(detections_cyclists, gt_labels_cyclists)\n",
    "\n",
    "detections = pd.DataFrame()\n",
    "detections = pd.concat([detections_vehicles, detections_pedestrians, detections_cyclists], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_detections_with_gt_boxes(detections, gt_labels_all, folder_name, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dtrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
